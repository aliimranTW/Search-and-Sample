# Search-and-Sample
This project focuses on the implementation of the three main features of a robot: perception, decision making and action. The implementation is done on a rover in a simulated environment similar to that of Mars. The rover is equipped with a 320x160 camera and a robotic arm to interact with the environment. The goal of the project is to enable the robot to explore the space and build a map of the surroundings in real-time.
1.  In the perception step, the task is to identify the surroundings by using computer vision techniques applied on the input from the camera. The robot must able to identify the traversable terrain, the objects present in the nearest neighborhood and non-traversable terrains. 
2. The next step is to develop an algorithm to enable the robot wander around autonomously, based on the information from the perception step. 
3. The last step is to combine the above-mentioned features and transfer it to the simulator so that the robot can act upon it. A video has been attached with the code to show the final result. 

The project has been implemented using python, solidifying the understanding of using functions and object-oriented programming. 
